<!DOCTYPE html>
<html lang="en">

<script src="bootstrap.js"></script>
<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script> 
<!---
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
--->
<script src="load-mathjax.js" async></script>
<link href='https://fonts.googleapis.com/css?family=Asap' rel='stylesheet'>


<style type="text/css">
body {
    font-family: "Asap", "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
}

@media screen and (min-width: 980px){
    body {
        width: 980px;
    }
}


h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #5364cc;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1 {
    text-align: center;
}
h2,h3 {
    text-align: left;
}

h1 {
    font-size: 36px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
h3 {
    font-weight: 600;
    margin: 16px 0px 4px 0px;
}

.paper-title {
    padding: 1px 0px 1px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}

.move-down {
    margin-top:0.6cm;
}

.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.col-1 {
     width: 100%;
     float: left;
}

.col-8{
width: 12.5%;
}

.author-row, .affil-row {
    font-size: 26px;
}

.author-row-new { 
    text-align: center; 
}

.author-row-new a {
    display: inline-block;
    font-size: 20px;
    padding: 4px;
}

.author-row-new sup {
    color: #313436;
    font-size: 12px;
}

.affiliations-new {
    font-size: 18px;
    text-align: center;
    width: 80%;
    margin: 0 auto;
    margin-bottom: 20px;
}

.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 26px;
}
.affiliatons {
    font-size: 18px;
}
.affil-row {
    margin-top: 18px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    color: #666;
    margin-top: 10px;
    margin-bottom: 20px;
	text-align: left;
}

.caption-up {
    font-size: 16px;
    color: #666;
    margin-top: -8px;
    margin-left: 50px;
    margin-bottom: 20px;
	text-align: left;
}

.caption-right {
    font-size: 16px;
    color: #666;
    margin-top: 0px;
    margin-left: 0px;
    margin-bottom: 30px;
	text-align: left;
}


video {
    display: block;
    margin: auto;
}


figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    padding: 0;
    margin: 0;
    list-style: none;
}

.paper-btn-coming-soon {
    position: relative; 
    top: 0;
    left: 0;
}

.coming-soon {
    position: absolute;
    top: -15px;
    right: -15px;
}

.center {
  margin-left: 10.0%;
  margin-right: 10.0%;
}

.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #5364cc;
  color: white !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.paper-btn:hover {
    opacity: 0.85;
}

.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}

.venue {
    font-size: 23px;
}

.topnav {
    background-color: #EEEEEE;
    overflow: hidden;
}

.topnav div {
    max-width: 1070px;
    margin: 0 auto;
}

.topnav a {
    display: inline-block;
    color: black;
    text-align: center;
    vertical-align: middle;
    padding: 16px 16px;
    text-decoration: none;
    font-size: 18px;
}

.topnav img {
    padding: 2px 0px;
    width: 100%;
    margin: 0.2em 0px 0.3em 0px;
    vertical-align: middle;
}

pre {
    font-size: 0.9em;
    padding-left: 7px;
    padding-right: 7px;
    padding-top: 3px;
    padding-bottom: 3px;
    border-radius: 3px;
    background-color: rgb(235, 235, 235);
    overflow-x: auto;
}

.download-thumb {
    display: flex;
}

@media only screen and (max-width: 620px) {
    .download-thumb {
        display: none;
    }
}

.paper-stuff {
    width: 50%;
    font-size: 20px;
}

@media only screen and (max-width: 620px) {
    .paper-stuff {
        width: 100%;
    }
}
* {
  box-sizing: border-box;
}

.column {
  text-align: center;
  float: left;
  width: 16.666%;
  padding: 5px;
}
.column3 {
  text-align: center;
  float: left;
  width: 33.333%;
  padding: 5px;
}
.column4 {
  text-align: center;
  float: left;
  width: 50%;
  padding: 5px;
}
.column5 {
  text-align: center;
  float: left;
  width: 20%;
  padding: 5px;
}
.column10 {
  text-align: center;
  float: left;
  width: 10%;
  padding: 5px;
}
.border-right {
    border-right: 1px solid black;
}
.border-bottom{
    border-bottom: 1px solid black;
}


.row-center {
    margin: 16px 0px 16px 0px;
    text-align: center;
}

/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}
.img-fluid {
  max-width: 100%;
  height: auto;
}
.figure-img {
  margin-bottom: 0.5rem;
  line-height: 1;
}

.rounded-circle {
  border-radius: 50% !important;
}

.image-container {
    text-align: center;
}

.image-container img {
    border: 2px solid black;
    width: 100%;
}

.image-container img:hover {
    opacity: 0.7;
}

.image-container .image-caption {
    text-align: center;
}


/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
  .column {
    width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .column3 {
    width: 100%;
  }
}

</style>
<link rel="stylesheet" href="bootstrap-grid.css">
<link rel="stylesheet" href="simplegrid.css">

<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <head>
        <title>InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:description" content="InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback"/>
        <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:creator" content="@jyangballin">
        <meta name="twitter:title" content="InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback">
        <meta name="twitter:description" content="">
        <meta name="twitter:image" content="">
    </head>

<body>

<div class="container">
    <div class="paper-title">
    <h1> 
        InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                <a href="john-b-yang.github.io">John Yang<sup>*</sup></a>
                <a href="https://aksh555.github.io/">Akshara Prabhakar<sup>*</sup></a>
                <a href="https://www.cs.princeton.edu/~karthikn/">Karthik Narasimhan</a>
                <a href="https://ysymyth.github.io/">Shunyu Yao</a>
            </div>
        </center>

        <center>
            <div class="author-row-new">
                Princeton University
            </div>
        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="https://arxiv.org/abs/2306.14898">
                <span class="material-icons"> description </span> <br/>
                 Paper
            </a>
            <a class="paper-btn" href="https://github.com/princeton-nlp/intercode">
                <span class="material-icons"> code </span><br/>
                Code
            </a>
            <a class="paper-btn" href="https://github.com/princeton-nlp/intercode/tree/master/data">
                <span class="material-icons"> folder </span><br/>
                Data
            </a>
            <a class="paper-btn" href="https://pypi.org/project/intercode-bench/">
                <span class="material-icons"> inventory_2 </span><br/>
                PyPI
            </a>
            </div>
        </div>
    </div>

    <center>
        <p>
            Build 
            <span style="color:orange">
                interactive code environments
            </span>
            for training, testing, and augmenting code and decision making agents
        </p>
    </center>

    <div style="padding-top: 10px">
        <figure>
            <center>
            <img width="100%" src="img/Preview-Small.png"> 
            </center>
            <p class="caption">
                <b>Overview of InterCode</b>. Setting up an interactive code environment with InterCode requires a
                Dockerfile, dataset, reward function definition, and a small amount of subclass implementation. The
                interactive loop between agent and environment closely mirrors real world software development processes.
            </p>
        </figure>
    </div>

    <section id="abstract">
        <hr>
        <h2>Abstract</h2>
        <div class="flex-row">
            <p>
                Humans write code in a fundamentally interactive manner and rely on constant execution feedback to correct errors, resolve ambiguities, and decompose tasks. While LLMs have recently exhibited promising coding capabilities, current coding benchmarks mostly consider a static instruction-to-code sequence transduction process, which has the potential for error propagation and a disconnect between the generated code and its final execution environment. To address this gap, we introduce InterCode, a lightweight, flexible, and easy-to-use framework of interactive coding as a standard reinforcement learning (RL) environment, with code as actions and execution feedback as observations. Our framework is language and platform agnostic, uses self-contained Docker environments to provide safe and reproducible execution, and is compatible out-of-the-box with traditional seq2seq coding methods, while enabling the development of new methods for interactive code generation. We use InterCode to create two interactive code environments with Bash and SQL as action spaces, leveraging data from the static Spider and NL2Bash datasets. We demonstrate InterCode's viability as a testbed by evaluating multiple state-of-the-art LLMs configured with different prompting strategies such as ReAct and Plan & Solve. Our results showcase the benefits of interactive code generation and demonstrate that InterCode can serve as a challenging benchmark for advancing code understanding and generation capabilities. InterCode is designed to be easily extensible and can even be used to incorporate new tasks such as Capture the Flag, a popular coding puzzle that is inherently multi-step and involves multiple programming languages.
            </p>
        </div>
    </section>

    <section id="formulation">
        <hr>
        <h2>Interactive Coding Task Formulation</h2>
        <div>
            <figure>
                <center>
                <img width="75%" src="img/Formulation.png"> 
                </center>
            </figure>
        </div>
        <div class="flex-row">
            <br>
            InterCode formalizes the interactive coding task as a partially observable Markov Decision Process (POMDP) that mirrors
            real world coding processes carried out by human developers.
            <br><br>
            InterCode provides a framework that enables the creation of interactive coding environments.
            At a high level, InterCode decomposes the construction of an interactive coding task into three
            modular parts: (1) environment construction, (2) data collection, and (3) reward design. This
            workflow allows for the safe execution of transition functions, flexible reward design, and convenient
            adaptation of existing instructions to an interactive setting.
        </div>
    </section>

    <section id="environments">
        <hr>
        <h2>Bash, SQL Environments</h2>
        <div class="flex-row">
            <p>
                We create two separate InterCode based environments where Bash and SQL are the action spaces respectively.
            </p>
        </div>
        <div>
            <h3>InterCode-Bash Environment</h3>
            <div class="flex-row">
                <div style="width:50%;padding:5px">
                    <img width="90%" src="img/Traj-Bash.png">
                </div>
                <div style="width:50%;padding:5px">
                    <img width="90%" src="img/Reward-Bash.png">
                </div>
            </div>
            <div class="flex-row">
                <p>
                    We define a <span style="color:orange">Bash Shell on Ubuntu Operating System</span> as the
                    task environment, along with four different file systems.
                    We bootstrap the <span style="color:orange">NL2Bash
                    <a href="https://github.com/TellinaTool/nl2bash">dataset</a></span>, making key tranformations to the data
                    to ground instructions and gold queries into the file system of our interactive setting.
                    Finally, we define a custom reward function that evalutes whether an agent completed the task based on
                    <span style="color:orange">file system modifications and the final execution output</span> of the program.
                </p>
            </div>
        </div>
        <div>
            <h3>InterCode-SQL Environment</h3>
            <div class="flex-row">
                <div style="width:50%;padding:5px">
                    <img width="90%" src="img/Traj-SQL.png">
                </div>
                <div style="width:50%;padding:5px">
                    <img width="90%" src="img/Reward-SQL.png">
                </div>
            </div>
            <div class="flex-row">
                <p>
                    We define a <span style="color:orange">SQL interpreter in a MySQL Databases</span> as the
                    task environment, along with four different file systems.
                    We bootstrap the <span style="color:orange">Spider
                    <a href="https://yale-lily.github.io/spider">dataset</a></span>, making key tranformations to convert SQLite
                    data to a MySQL format to be compatible with our interactive setting.
                    Finally, we define a custom reward function that evalutes whether an agent completed the task based on an
                    <span style="color:orange">Intersection over Union</span> comparison of the latest execution output of
                    an agent and the reference gold command.
                </p>
            </div>
        </div>
    </section>

    <section id="methods">
        <hr>
        <h2>Methods</h2>
        <div class="flex-row">
            <p>
                We evaluate several prompting strategies on a suite of large language models
                [OpenAI (text-davinci-003, gpt-3.5-turbo, gpt-4), PaLM-2204 (text-bison-001, chat-bison-001),
                and Open Source (Vicuna-13B, StarChat-16B)] on the Bash and SQL interactive coding tasks.
            </p>
        </div>
        <div>
            <figure>
                <center>
                <img width="85%" src="img/Approaches.png"> 
                </center>
            </figure>
        </div>
    </section>

    <section id="experiments">
        <hr>
        <h2>Experiments</h2>
        <div class="flex-row">
            <h3>Key Takeaways</h3>
            <p>
                1) From our comparison of base models with Single Turn and Try Again mode, we note that performance on task of generating 
                correct answer to an instruction using code is vastly superior in an interactive setting.
            </p>
            <div class="flex-row">
                <div style="width:50%;padding:5px">
                    <img width="100%" src="img/Results-SQL.png">
                </div>
                <div style="width:50%;padding:5px">
                    <img width="100%" src="img/Results-Bash.png">
                </div>
            </div>
            <p class="caption">
                (Left) Success Rate for single vs. multi turn evaluation on InterCode-SQL. Query difficulty is adopted from Spider.
                (Right) Success Rate across across file systems for single vs. multi turn evaluation on InterCode-Bash.
                Success Rate is defined as the proportion of tasks where the reward received is 1 (agent successfully completed the task).
                Best metrics are bolded.
            </p>
            <p>
                2) From our comparison of different prompting strategies using the GPT-3.5 base model, we observe that A. Different tasks present
                different learning challenges and B. More adaptive reasoning techniques are favorable.
            </p>
            <figure>
                <center>
                <img width="50%" src="img/Results-Prompts.png"> 
                </center>
            </figure>
            <p class="caption">
                Comparison of different prompting strategies across the entire InterCode-SQL and InterCode- Bash datasets using gpt-3.5-turbo
                as the base model. Turns refers to the average number of turns taken for a single task episode. For Try Again and ReAct, the
                max number of turns n = 10. Error Rate is defined as the percentage of non-admissible actions taken by the agent, where
                admissible refers to action that can be parsed and executed by a compiler/interpreter.
                The highest Success Rate, fewest Turns, and lowest Error % are highlighted per dataset since they
                reflect more accuracy and efficient task solving. Best metrics are in bold.
            </p>
            <p>
                3) We curate a toy dataset of easy CTF objectives from <a href="https://picoctf.org/">picoCTF</a>, where each task instance is
                a &lt;challenge description, hidden flag&gt; pair, to demontrate InterCode's utility as a framework for devising new tasks and
                datasets with novel code understanding and interaction challenges.
            </p>
            <figure>
                <center>
                <img width="100%" src="img/Traj-ctf.png"> 
                </center>
            </figure>
        </div>
    </section>

    <section id="citation">
        <hr>
        <h2>Citation</h2>
        <div class="language-plaintext highlighter-rouge">
            <pre class="highlight" style="padding-left:1em;padding-right:1em;">
                <code>
@inproceedings{yang2023intercode,
    title = {InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback},
    author = {Yang, John and Prabhakar, Akshara and Narasimhan, Karthik and Yao, Shunyu},
    booktitle = {ArXiv},
    year = {2023},
    html = {https://arxiv.org/abs/2306.14898}
}</code>
            </pre>
        </div>
    </section>

    <footer style="padding-bottom:2.5em">
        <hr style="padding-bottom:1em">
        <a href="https://github.com/intercode-benchmark/intercode-benchmark.github.io">InterCode</a>
        is maintained by
        <a href="https://github.com/princeton-nlp">princeton-nlp</a>.
    </footer>
</div>

</body>
</html>
